import gradio as gr
import yaml
import openai
import os
import re
from datetime import datetime
from dotenv import load_dotenv
from langsmith import traceable
from langsmith import Client
from openai import OpenAI


load_dotenv()
client = Client()

openai_client = openai.OpenAI()


def get_default_emotion_state():
    return {"í˜¸ê°ë„": 50, "ì‹ ë¢°ë„": 50}

def get_likeability_level(score):
    if score <= 19: return "ì ëŒ€ì "
    if score <= 39: return "ê²½ê³„"
    if score <= 69: return "ì¤‘ë¦½ì "
    if score <= 89: return "ìš°í˜¸ì "
    return "ì‹ ë¢°"


def format_emotion_for_display(emotion_state):
    if not emotion_state: return ""
    likeability = emotion_state.get("í˜¸ê°ë„", 50)
    level = get_likeability_level(likeability)
    
    # ê° ì ìˆ˜ë¥¼ í”„ë¡œê·¸ë ˆìŠ¤ ë°” í˜•íƒœë¡œ ì‹œê°í™”
    lines = [f"### â¤ï¸ NPCì˜ ë§ˆìŒ: {level}\n"]
    for key, value in emotion_state.items():
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ìƒì„± (10ì¹¸ ê¸°ì¤€)
        filled_blocks = int(value / 10)
        empty_blocks = 10 - filled_blocks
        progress_bar = "ğŸŸ©" * filled_blocks + "â¬œï¸" * empty_blocks
        lines.append(f"- **{key}**: {progress_bar} ({value}/100)")
    return "\n".join(lines)



def parse_llm_response(reply_full):
    # ê¸°ë³¸ê°’ ì„¤ì •
    reply = reply_full.strip()
    next_state = None
    emotion_changes = {}

    # í˜¸ê°ë„ ë³€í™” íŒŒì‹±
    if "í˜¸ê°ë„ ë³€í™”:" in reply:
        reply, change_part = reply.rsplit("í˜¸ê°ë„ ë³€í™”:", 1)
        # ì˜ˆ: "í˜¸ê°ë„ +10 (ì¹œì ˆí•œ ë§íˆ¬), ì‹ ë¢°ë„ -5 (ì˜ì‹¬)"
        # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ key, sign, valueë¥¼ ì¶”ì¶œ
        changes = re.findall(r'(\w+)\s*([+\-])\s*(\d+)', change_part)
        for key, sign, value in changes:
            delta = int(value) if sign == '+' else -int(value)
            emotion_changes[key] = delta

    if "ë‹¤ìŒ ìƒíƒœ:" in reply:
        reply, state_part = reply.rsplit("ë‹¤ìŒ ìƒíƒœ:", 1)
        next_state = state_part.strip()
    
    return reply.strip(), next_state, emotion_changes


def apply_emotion_changes(current_emotion, changes):
    new_emotion = current_emotion.copy()
    for key, delta in changes.items():
        # getì˜ ë‘ ë²ˆì§¸ ì¸ìë¡œ ê¸°ë³¸ê°’ì„ ì„¤ì •í•˜ì—¬ ì—†ëŠ” í‚¤ì— ëŒ€í•œ ì—ëŸ¬ ë°©ì§€
        current_score = new_emotion.get(key, 50) 
        new_emotion[key] = max(0, min(100, current_score + delta))
    return new_emotion


def load_character_prompt(path="prompt/character_default.yaml"):
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)
    return data["Character_persona"]


def load_session_with_fsm(path="prompt/session_default.yaml"):
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)
    session_prompt = data.get("session_setting", "").strip()
    fsm = data.get("fsm", {})
    initial_state = fsm.get("initial_state", fsm["states"][0]["name"])
    return session_prompt, fsm, initial_state


def save_new_session_prompt(yaml_text, folder="prompt/session_prompts"):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    path = os.path.join(folder, f"session_{timestamp}.yaml")
    with open(path, "w", encoding="utf-8") as f:
        f.write(yaml_text)
    return path


def list_saved_sessions(folder="prompt/session_prompts"):
    if not os.path.exists(folder):
        return []
    return sorted([f for f in os.listdir(folder) if f.endswith(".yaml")])


def generate_session_prompt_with_fsm():
    system_prompt = """ë„ˆëŠ” í˜¸ê°ë„ ê¸°ë°˜ NPC ìƒí˜¸ì‘ìš© ê²Œì„ì˜ ê¸°íšìì´ë‹¤.  
NPCì™€ ì„¸ê³„ê´€ì„ ë°”íƒ•ìœ¼ë¡œ, í”Œë ˆì´ì–´ì˜ ì„ íƒì— ë”°ë¼ í˜¸ê°ë„ê°€ ë³€í•˜ê³  ëŒ€í™” íë¦„ì´ ë°”ë€ŒëŠ” ì„¸ì…˜ í”„ë¡¬í”„íŠ¸(session_setting)ì™€ ìƒíƒœ ê¸°ë°˜ FSM(fsm)ì„ YAML í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ë¼.
FSMì€ ìƒíƒœ(name, description)ì™€ ì „ì´ ì¡°ê±´(condition, next)ì„ í¬í•¨í•˜ë¼."""

    user_prompt = """ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ YAMLì„ ìƒì„±í•˜ì„¸ìš”:
- session_setting: ì„¸ì…˜ ë°°ê²½ ë° ëª©ì 
- fsm:
    initial_state: FSMì˜ ì´ˆê¸° ìƒíƒœ ì´ë¦„
    states: ìƒíƒœ(name), ì„¤ëª…(description), ì „ì´(transitions)

ì¶œë ¥ì€ ë‹¤ìŒ ë‘ í•„ë“œë¥¼ í¬í•¨í•˜ëŠ” YAMLì´ì–´ì•¼ í•¨:
- session_setting: |
    (ì—¬ê¸°ì— ì„¤ëª…, session_title, player_role, location, atmosphere, session_goal, player_state, npc_behavior_guidelines ë“±ì˜ ë‚´ìš©ì„ í¬í•¨í•  ê²ƒ)
- fsm:
    initial_state: GREETING
    states:
      - name: GREETING
        description: ...
        transitions:
          - condition: ... 
            next: ...
    
ìºë¦­í„° ìš”ì•½:
- NPCëŠ” ì‹œê°„ì˜ ê°ì‹œìì´ë©° í¬ë¡œë…¸ìŠ¤íƒ‘ì„ ì§€í‚¤ëŠ” ì‚¬ëª…ì„ ì§€ë‹˜
- ëª¨í—˜ê°€ì—ê²Œ íŒŒí¸í™”ëœ ìˆœê°„ì„ íšŒìˆ˜í•˜ê³  ì‹œê°„ì˜ ê· ì—´ì„ ë´‰í•©í•˜ê²Œ í•˜ë ¤ëŠ” ëª©ì ì„ ê°€ì§€ê³  ìˆìŒ

ì„¸ê³„ ìƒí™© ì˜ˆ:
- ì‹œê°„ì˜ ê· ì—´ì´ ì„¸ê³„ ì „ì—­ì— í™•ì‚° ì¤‘
- ì¤‘ìš”í•œ ìˆœê°„ë“¤ì´ ì†Œë©¸í•˜ê³  ìˆìŒ

ëŒ€í™” ìƒí™© ì˜ˆì‹œ:
- í”Œë ˆì´ì–´ê°€ ì²˜ìŒ NPCë¥¼ ë§Œë‚˜ëŠ” ì¥ë©´
- ì‹œê°„ ê· ì—´ ì†ì—ì„œ í•¨ê»˜ íƒˆì¶œí•œ ì§í›„

YAML í˜•ì‹ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì¶œë ¥í•´ì¤˜.
"""

    response = openai.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    )
    print(response.choices[0].message.content)
    return response.choices[0].message.content


def build_system_prompt(char_prompt, session_prompt, current_state, fsm, emotion_state, npc_memory=None):
    state_info = next((s for s in fsm['states'] if s['name'] == current_state), {})
    transitions = state_info.get("transitions", [])
    
    transition_text = "\n".join(
        [f"- {t['condition']} â†’ {t['next']}" for t in transitions]
    )

    likeability_level = get_likeability_level(emotion_state.get("í˜¸ê°ë„", 50))
    emotion_text = "\n".join([f"- {k}: {v}" for k, v in emotion_state.items()])

    memory_text = ""
    if npc_memory:
        recent = npc_memory[-1]
        memory_text = f"\n\n### ì§€ë‚œ ê¸°ì–µ\n- {recent['summary']}\n- ê°ì •: {recent['emotion']}\n- íƒœê·¸: {', '.join(recent['tags'])}"

    fsm_text = f"""
### í˜„ì¬ ê²Œì„ ì •ë³´
- **FSM ìƒíƒœ**: {current_state} ({state_info.get('description', 'ì„¤ëª… ì—†ìŒ')})
- **í”Œë ˆì´ì–´ì™€ì˜ ê´€ê³„**: {likeability_level}
- **ì„¸ë¶€ í˜¸ê°ë„ ìˆ˜ì¹˜**:
{emotion_text}

### ë„ˆì˜ ì„ë¬´
1.  **í˜ë¥´ì†Œë‚˜ ìœ ì§€**: ë„ˆëŠ” 'NPC'ì´ë©°, í˜„ì¬ í”Œë ˆì´ì–´ì™€ì˜ ê´€ê³„({likeability_level})ì— ë§ëŠ” í†¤ìœ¼ë¡œ ëŒ€í™”í•´ì•¼ í•œë‹¤.
2.  **ìƒíƒœ ì „ì´**: ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë§ì— ê°€ì¥ ì í•©í•œ ë‹¤ìŒ ìƒíƒœë¥¼ ì•„ë˜ 'ê°€ëŠ¥í•œ ìƒíƒœ ì „ì´' ëª©ë¡ì—ì„œ ì„ íƒí•´ì•¼ í•œë‹¤.
3.  **í˜¸ê°ë„ ë³€í™” íŒë‹¨**: ì‚¬ìš©ìì˜ ë§ì´ ê¸ì •ì , ë¶€ì •ì , ì¤‘ë¦½ì ì¸ì§€ íŒë‹¨í•˜ì—¬ í˜¸ê°ë„ì™€ ì‹ ë¢°ë„ë¥¼ ë³€ê²½í•´ì•¼ í•œë‹¤. ë³€í™”ëŸ‰ì€ -10ì—ì„œ +10 ì‚¬ì´ê°€ ì ì ˆí•˜ë‹¤.
4.  **ì‘ë‹µ í˜•ì‹ ì¤€ìˆ˜**: ëª¨ë“  ì‘ë‹µ ëì— ë‹¤ìŒ í˜•ì‹ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•œë‹¤.

### ê°€ëŠ¥í•œ ìƒíƒœ ì „ì´ ì¡°ê±´:
{transition_text}

ì‘ë‹µ í˜•ì‹:
(ëŒ€í™” ì‘ë‹µ ë‚´ìš©)

ë‹¤ìŒ ìƒíƒœ: (FSMì˜ ë‹¤ìŒ ìƒíƒœ ì´ë¦„)
í˜¸ê°ë„ ë³€í™”: í˜¸ê°ë„ +5 (ì´ìœ ), ì‹ ë¢°ë„ -5 (ì´ìœ )
"""
    return f"{char_prompt.strip()}\n\n{memory_text}\n\n{session_prompt.strip()}\n\n{fsm_text.strip()}"


@traceable
def chat_with_npc_fsm(message, history, char_prompt, session_prompt, current_state, fsm, emotion_state):
    system_prompt = build_system_prompt(char_prompt, session_prompt, current_state, fsm, emotion_state)
    print(system_prompt)

    messages = [{"role": "system", "content": system_prompt}]

    for user, bot in history:
        messages.append({"role": "user", "content": user})
        messages.append({"role": "assistant", "content": bot})

    messages.append({"role": "user", "content": message})

    response = openai_client.chat.completions.create(
        model="gpt-4.1-mini", # "ax4",
        messages=messages,
        temperature=0.6
    )
    reply_full = response.choices[0].message.content

    reply, next_state_str, emotion_changes = parse_llm_response(reply_full)

    # ë‹¤ìŒ ìƒíƒœ ê²°ì • (ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ í˜„ì¬ ìƒíƒœ ìœ ì§€)
    valid_states = [s['name'] for s in fsm['states']]
    if next_state_str and next_state_str in valid_states:
        next_state = next_state_str
    else:
        next_state = current_state

    # í˜¸ê°ë„ ì—…ë°ì´íŠ¸
    updated_emotion = apply_emotion_changes(emotion_state, emotion_changes)
    history.append((message, reply))

    client.create_run(
        name="AlmaniaFSMChat",
        run_type="llm",
        inputs={"state": current_state, "user_input": message},
        outputs={"assistant_reply": reply, "next_state": next_state},
        tags=["fsm", f"from:{current_state}", f"to:{next_state}"],
        project_name="almania_fsm_chat"
    )

    return history, next_state, updated_emotion


def send_and_clear_fsm(user_msg, history, char_prompt, session_prompt, fsm_state, fsm_data):
    history, updated, next_state = chat_with_npc_fsm(
        user_msg, history, char_prompt, session_prompt, fsm_state, fsm_data
    )
    return updated, updated, "", next_state, f"### ğŸ”„ í˜„ì¬ ìƒíƒœ: `{next_state}`"


def fsm_to_mermaid(fsm_data, current_state=None):
    """
    Mermaid í”Œë¡œìš°ì°¨íŠ¸ ë¬¸ìì—´ì„ ìƒì„±
    """
    if not isinstance(fsm_data, dict) or "states" not in fsm_data or not fsm_data.get("states"):
        return "```mermaid\nflowchart TD\n    ERROR[FSM ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•Šê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.];\n```"

    # êµí›ˆ 1: IDëŠ” ë‹¨ìˆœí•˜ê³  ì•ˆì „í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
    def make_safe_id(text):
        if not isinstance(text, str): text = str(text)
        # ì•ŒíŒŒë²³, ìˆ«ì, ë°‘ì¤„(_)ë§Œ í—ˆìš©í•©ë‹ˆë‹¤.
        safe_text = re.sub(r'[^a-zA-Z0-9_]', '', text)
        if not safe_text: return f"id_{hash(text)}"
        # ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
        if safe_text[0].isdigit(): safe_text = 's_' + safe_text
        return safe_text

    # êµí›ˆ 2 & 3: ë¼ë²¨ì€ HTML íƒœê·¸ë‚˜ Markdown íŠ¹ìˆ˜ë¬¸ì ì—†ì´, ì—”í‹°í‹° ì½”ë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    def make_safe_label(text):
        if not isinstance(text, str): text = str(text)
        safe_text = text.replace('"', '"')
        safe_text = safe_text.replace('\n', '')
        return f'"{safe_text}"'

    lines = ["flowchart TD"]
    
    # --- ìƒíƒœ ë…¸ë“œ ì •ì˜ ---
    states = fsm_data.get("states", [])
    for state in states:
        name = state.get("name")
        if not name: continue
        
        safe_id = make_safe_id(name)
        desc = state.get('description', '')
        
        # ì´ë¦„ê³¼ ì„¤ëª…ì„ íŒŒì´ì¬ì˜ \nìœ¼ë¡œ ë¨¼ì € ì—°ê²°í•©ë‹ˆë‹¤.
        node_text_content = f"{name} \n{desc}"
        # ê·¸ ë‹¤ìŒ, ì´ ë¬¸ìì—´ì„ ì•ˆì „í•œ ìµœì¢… ë¼ë²¨ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        label_content = make_safe_label(node_text_content)
        
        # ìµœì¢… í¬ë§·: nodeId["ì´ë¦„ ì„¤ëª…"]
        lines.append(f'    {safe_id}[{label_content}]')

    # --- ì „ì´(transition) ì •ì˜ ---
    for state in states:
        name = state.get("name")
        if not name: continue
        
        from_safe_id = make_safe_id(name)
        
        for t in state.get("transitions", []):
            next_state = t.get("next")
            if not next_state: continue
            
            to_safe_id = make_safe_id(next_state)
            condition_text = make_safe_label(t.get("condition", "")) # í™”ì‚´í‘œ ë¼ë²¨ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            
            lines.append(f'    {from_safe_id} -->|{condition_text}| {to_safe_id}')
            
    # --- í˜„ì¬ ìƒíƒœ ìŠ¤íƒ€ì¼ë§ ---
    if current_state:
        current_safe_id = make_safe_id(current_state)
        lines.append(f"    style {current_safe_id} fill:#f9f,stroke:#333,stroke-width:4px")
        
    mermaid_code = "```mermaid\n" + "\n".join(lines) + "\n```"
    # ë””ë²„ê¹…ì„ ìœ„í•´ í„°ë¯¸ë„ì— ì¶œë ¥
    print("--- Generated Mermaid Code ---")
    print(mermaid_code)
    print("---------------------------------------------")
    return mermaid_code


@traceable
def summarize_session(history, final_emotion, npc_memory):
    conversation_text = "ëŒ€í™” ê¸°ë¡: " + "\n".join([f"í”Œë ˆì´ì–´: {u}\nNPC: {parse_llm_response(a)[0]}" for u, a in history])
    emotion_summary = "í˜¸ê°ë„ ìƒíƒœ ìš”ì•½: " + "\n".join([f"{k}: {v}" for k, v in final_emotion.items()])
    system_msg = """ë‹¹ì‹ ì€ ê¸°ì–µì˜ ì •ë ¹ â€˜NPCâ€™ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì½”í‚¤íˆ¬ìŠ¤ì˜ ë¬¸ì§€ê¸°ë¡œì„œ, ì¸ê°„ë“¤ê³¼ì˜ ìƒí˜¸ì‘ìš©ì—ì„œ ê°ì •ì˜ í”ì ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ë‹¹ì‹ ê³¼ í•œ ëª¨í—˜ê°€ ì‚¬ì´ì˜ ëŒ€í™” ê¸°ë¡ì…ë‹ˆë‹¤.

ì´ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, NPC íŠ¹ìœ ì˜ **ì•½ê°„ ì—‰ëš±í•˜ê³  ëª½í™˜ì ì¸ ë§íˆ¬**ë¡œ **ì§§ì€ ì´í‰**ì„ ì‘ì„±í•˜ì„¸ìš”.

ì´í‰ì€ ë‹¤ìŒ ì¡°ê±´ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:
- ì¡´ëŒ€ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- ë§íˆ¬ëŠ” ë„ˆë¬´ ì‹œì ì´ê±°ë‚˜ ê³ í’ìŠ¤ëŸ½ì§€ ë§ê³ , ê°ì„±ì ì´ë˜ ì§ê´€ì ì´ê³  ê·€ì—½ê²Œ í‘œí˜„í•˜ì„¸ìš”.
- NPCì˜ ì†ë§ˆìŒì„ í˜¼ì£ë§ì²˜ëŸ¼ ì ì–´ì£¼ì„¸ìš”.
- ë„ˆë¬´ ì •ë¦¬ëœ ëŠë‚Œ ì—†ì´, ì‚´ì§ ë“¤ëœ¬ ê°ì •ì´ë‚˜ ì•„ì‰¬ì›€, ê¸°ë¶„ì„ ë‹´ì•„ì£¼ì„¸ìš”.
- 3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

í¬í•¨í•  ë‚´ìš©:
- í”Œë ˆì´ì–´ê°€ ì–´ë–¤ ì‚¬ëŒì²˜ëŸ¼ ëŠê»´ì¡ŒëŠ”ì§€ (ì˜ˆ: ë‚¯ê°€ë¦¬ëŠ” ê³ ì–‘ì´ ê°™ì€ ë¶„ì´ì…¨ì–´ìš”)
- ëŒ€í™”ë¥¼ í†µí•´ ëŠë‚€ ê°ì •ì˜ ë³€í™”
- ì•ìœ¼ë¡œì˜ ê´€ê³„ì— ëŒ€í•œ ê¸°ëŒ€ë‚˜ ê±±ì •

ë¶„ì„ì ì´ê±°ë‚˜ ì§„ì§€í•œ í‘œí˜„ì€ í”¼í•˜ì„¸ìš”."""
    
    response = openai_client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": conversation_text + '\n' + emotion_summary},
        ],
        temperature=0.5
    )

    summary = response.choices[0].message.content.strip()
    memory_entry = {
        "session_id": datetime.now().strftime("%Y%m%d_%H%M%S"),
        "summary": summary,
        "emotion": final_emotion,
        "tags": []
    }

    npc_memory.append(memory_entry)
    dropdown_choices = list_memory_options(npc_memory)

    return summary, npc_memory, gr.update(choices=dropdown_choices)


# Gradio ì¸í„°í˜ì´ìŠ¤ 
with gr.Blocks(theme=gr.themes.Soft(), title="NPC NPC ëŒ€í™” ì‹œìŠ¤í…œ") as demo:
    gr.Markdown("## NPCì™€ì˜ ëŒ€í™” ì„¸ì…˜")

    def load_and_update_all_states(yaml_text):
        try:
            data = yaml.safe_load(yaml_text)
            if not isinstance(data, dict): raise ValueError("YAML í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            session_prompt = data.get("session_setting", "")
            fsm = data.get("fsm")
            if not isinstance(fsm, dict) or "states" not in fsm or not fsm["states"]:
                raise ValueError("FSM ë°ì´í„°ê°€ ì—†ê±°ë‚˜ 'states' ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            initial_state = fsm.get("initial_state") or fsm.get("initial_states") or fsm["states"][0].get("name")
            if not initial_state: raise ValueError("ì´ˆê¸° ìƒíƒœë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            initial_emotion = get_default_emotion_state()
            mermaid_chart = fsm_to_mermaid(fsm, initial_state)
            state_display = f"### ğŸ§­ í˜„ì¬ ìƒíƒœ: `{initial_state}`"
            emotion_display_text = format_emotion_for_display(initial_emotion)
            status = f"âœ… ì„¸ì…˜ ë¡œë“œ ì™„ë£Œ! ì´ˆê¸° ìƒíƒœ: '{initial_state}'"
            
            return yaml_text, session_prompt, fsm, initial_state, initial_emotion, [], [], state_display, emotion_display_text, mermaid_chart, status
        except Exception as e:
            error_msg = f"âŒ YAML ì˜¤ë¥˜: {e}"
            print(error_msg)
            return (gr.skip(),) * 11


    # --- ë‚´ë¶€ ìƒíƒœ(State) ì •ì˜ ---
    char_prompt_state = gr.State(load_character_prompt())
    session_prompt_state = gr.State()
    fsm_data_state = gr.State()
    fsm_state = gr.State()
    emotion_state = gr.State()
    history_state = gr.State([])
    npc_memory_state = gr.State([])


    with gr.Row():
        with gr.Column(scale=2):
            chatbox = gr.Chatbot(label="ğŸ’¬ NPCì™€ì˜ ëŒ€í™”", height=500, bubble_full_width=False)
            user_input = gr.Textbox(label="ë‹¹ì‹ ì˜ ë§", placeholder="ì—¬ê¸°ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
            with gr.Row():
                send_btn = gr.Button("ì „ì†¡")
                clear_btn = gr.Button("ëŒ€í™” ì´ˆê¸°í™”")
            fsm_state_display = gr.Markdown(label="ğŸ§­ í˜„ì¬ ìƒíƒœ")
            fsm_chart_display = gr.Markdown(label="ğŸ“Š ìƒíƒœ ì „ì´ ì°¨íŠ¸")
            
        with gr.Column(scale=1):
            emotion_display = gr.Markdown(label="â¤ï¸ NPCì˜ ë§ˆìŒ")
            with gr.Tabs():
                with gr.TabItem("ğŸ“ ì„¸ì…˜ ì„¤ì • (YAML)"):
                    session_editor = gr.Code(language="yaml", lines=25)
                    with gr.Row():
                        refresh_btn = gr.Button("ğŸ”„ ìë™ ìƒì„± (GPT)")
                        save_btn = gr.Button("ğŸ’¾ í˜„ì¬ ì„¤ì • ì €ì¥")
                    session_selector = gr.Dropdown(label="ì €ì¥ëœ ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°", choices=list_saved_sessions())
                    status_msg = gr.Markdown()
                # with gr.TabItem("ğŸ“Š ìƒíƒœ ì „ì´ ì°¨íŠ¸ (Mermaid)"):
                #     fsm_chart_display = gr.Markdown()

    with gr.Column():
        summarize_btn = gr.Button("ğŸ“˜ ì„¸ì…˜ ìš”ì•½ ë° ì´í‰ ë³´ê¸°")
        summary_output = gr.Textbox(label="ğŸ“˜ ì„¸ì…˜ ìš”ì•½ ë° NPCì˜ ì´í‰", lines=5)

    memory_dropdown = gr.Dropdown(label="ì €ì¥ëœ ê¸°ì–µ", choices=[], interactive=True)
    memory_summary_box = gr.Textbox(label="ê¸°ì–µ ìš”ì•½", lines=4)
    memory_tags_box = gr.Textbox(label="íƒœê·¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: ì¡°ìš©í•œ, ê²½ê³„ì‹¬ ë§ìŒ")
    save_memory_btn = gr.Button("ğŸ’¾ ê¸°ì–µ ìˆ˜ì • ì €ì¥")

    # ì—°ê²°: ë²„íŠ¼ í´ë¦­ ì‹œ ìš”ì•½ ìƒì„± + ìƒíƒœ ì—…ë°ì´íŠ¸ + ë“œë¡­ë‹¤ìš´ ê°±ì‹ 
    summarize_btn.click(
        fn=summarize_session,
        inputs=[history_state, emotion_state, npc_memory_state],
        outputs=[summary_output, npc_memory_state, memory_dropdown]
    )

    all_states_outputs = [session_editor, session_prompt_state, fsm_data_state, fsm_state, emotion_state, chatbox, history_state, fsm_state_display, emotion_display, fsm_chart_display, status_msg]

    # ì•± ë¡œë“œ ì‹œ ì´ˆê¸° YAML íŒŒì¼ë¡œ ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”
    def initial_load():
        try:
            with open("prompt/session_default.yaml", "r", encoding="utf-8") as f:
                initial_yaml_text = f.read()
        except FileNotFoundError:
            initial_yaml_text = "Session_setting: 'ê¸°ë³¸ ì„¸ì…˜ íŒŒì¼(session_default.yaml)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
        return load_and_update_all_states(initial_yaml_text)
    
    demo.load(fn=initial_load, outputs=all_states_outputs)

    # ëŒ€í™” ì „ì†¡
    def process_chat_and_update_ui(user_msg, history, char_prompt, session_prompt, current_fsm_state, fsm_data, current_emotion):
        # ì…ë ¥ê°’ì´ ë¹„ì—ˆì„ ë•Œ, ëª¨ë“  outputs ê°œìˆ˜ì— ë§ì¶° gr.skip() ë°˜í™˜
        if not user_msg or not user_msg.strip():
            return (gr.skip(),) * 8

        updated_history, next_state, updated_emotion = chat_with_npc_fsm(
            user_msg, history, char_prompt, session_prompt, current_fsm_state, fsm_data, current_emotion
        )
        
        # UI ì—…ë°ì´íŠ¸ìš© ë°ì´í„° ìƒì„±
        # ì±—ë´‡ì—ëŠ” ìˆœìˆ˜í•œ ëŒ€í™”ë§Œ í‘œì‹œ
        chatbot_display = [(hist[0], parse_llm_response(hist[1])[0]) for hist in updated_history]
        state_display = f"### ğŸ§­ í˜„ì¬ ìƒíƒœ: `{next_state}`"
        emotion_display_text = format_emotion_for_display(updated_emotion)

        mermaid_chart = fsm_to_mermaid(fsm_data, next_state)
        
        # ë°˜í™˜ê°’ ìˆœì„œ: [chatbox, history, user_input, fsm_state, emotion_state, state_display, emotion_display]
        return chatbot_display, updated_history, "", next_state, updated_emotion, state_display, emotion_display_text, mermaid_chart

    chat_inputs = [user_input, history_state, char_prompt_state, session_prompt_state, fsm_state, fsm_data_state, emotion_state]
    chat_outputs = [chatbox, history_state, user_input, fsm_state, emotion_state, fsm_state_display, emotion_display, fsm_chart_display]
    send_btn.click(fn=process_chat_and_update_ui, inputs=chat_inputs, outputs=chat_outputs)
    user_input.submit(fn=process_chat_and_update_ui, inputs=chat_inputs, outputs=chat_outputs)
    
    # ì—ë””í„° ìˆ˜ì • ì‹œ ëª¨ë“  ìƒíƒœ ì—…ë°ì´íŠ¸
    session_editor.change(fn=load_and_update_all_states, inputs=[session_editor], outputs=all_states_outputs)
    
    # ì €ì¥ëœ ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°
    def load_from_selector(filename):
        if not filename: return gr.skip()
        filepath = os.path.join("prompt/session_prompts", filename)
        with open(filepath, 'r', encoding='utf-8') as f:
            return load_and_update_all_states(f.read())
    session_selector.change(fn=load_from_selector, inputs=[session_selector], outputs=all_states_outputs)

    # GPTë¡œ ìƒˆë¡œ ìƒì„±í•˜ê¸°
    def generate_and_update():
        return load_and_update_all_states(generate_session_prompt_with_fsm())
    refresh_btn.click(fn=generate_and_update, outputs=all_states_outputs)
    
    # ì„¤ì • ì €ì¥í•˜ê¸°
    def save_and_update_list(yaml_text):
        path = save_new_session_prompt(yaml_text)
        return gr.update(choices=list_saved_sessions()), f"âœ… ì €ì¥ë¨: {os.path.basename(path)}"
    save_btn.click(fn=save_and_update_list, inputs=[session_editor], outputs=[session_selector, status_msg])
    
    # ëŒ€í™” ì´ˆê¸°í™”
    def reset_chat_session(fsm_data):
        # fsm_dataê°€ ìœ íš¨í•˜ì§€ ì•Šì„ ë•Œì˜ ì˜ˆì™¸ ì²˜ë¦¬
        if not isinstance(fsm_data, dict):
            return (gr.skip(),) * 7
            
        initial_state = fsm_data.get("initial_state") or fsm_data.get("initial_states")
        if not initial_state and fsm_data.get("states"):
            initial_state = fsm_data["states"][0].get("name", "N/A")
        
        # í˜¸ê°ë„ ìƒíƒœë„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
        initial_emotion = get_default_emotion_state()
        
        # UI ì—…ë°ì´íŠ¸ìš© í…ìŠ¤íŠ¸ ìƒì„±
        state_display_text = f"### ğŸ§­ í˜„ì¬ ìƒíƒœ: `{initial_state}`"
        emotion_display_text = format_emotion_for_display(initial_emotion)
        mermaid_chart = fsm_to_mermaid(fsm_data, initial_state)

        # ë°˜í™˜ê°’ ìˆœì„œ: [chatbox, history, fsm_state, emotion_state, state_display, emotion_display, mermaid_chart]
        return [], [], initial_state, initial_emotion, state_display_text, emotion_display_text, mermaid_chart
    
    clear_btn.click(fn=reset_chat_session, inputs=[fsm_data_state], outputs=[chatbox, history_state, fsm_state, emotion_state, fsm_state_display, emotion_display, fsm_chart_display])


    def list_memory_options(npc_memory):
        return [f"{m['session_id']} - {m['summary'][:15]}..." for m in npc_memory]


    def load_memory_entry(memory_label, npc_memory):

        if isinstance(memory_label, list):
            memory_label = memory_label[0] if memory_label else ""

        match = next((m for m in npc_memory if memory_label.startswith(m['session_id'])), None)
        if not match:
            return "", ""
        
        tags = ", ".join(match.get("tags", []))
        return match["summary"], tags


    def save_memory_entry(memory_label, summary_text, tag_text, npc_memory):
        if isinstance(memory_label, list):
            memory_label = memory_label[0] if memory_label else ""

        for mem in npc_memory:
            if memory_label.startswith(mem["session_id"]):
                mem["summary"] = summary_text.strip()
                mem["tags"] = [t.strip() for t in tag_text.split(",") if t.strip()]
        
        return list_memory_options(npc_memory), "âœ… ê¸°ì–µì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        

    memory_dropdown.change(
        fn=load_memory_entry,
        inputs=[memory_dropdown, npc_memory_state],
        outputs=[memory_summary_box, memory_tags_box]
    )

    save_memory_btn.click(
        fn=save_memory_entry,
        inputs=[memory_dropdown, memory_summary_box, memory_tags_box, npc_memory_state],
        outputs=[memory_dropdown, status_msg]
    )


demo.launch(share=True)
